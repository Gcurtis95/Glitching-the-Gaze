# Stable Diffusion 1.5 Standard loRa

This loRA was trained on cropped 832 x 1216 portrait and vice versa landscape images for stable diffusion 1.5. Trying to get the loRA to replicate the style as with SDXL. 
I experimented with inducing glitches into the generation by using low sampling steps.  Below are some results from experiments where the sampling step was changed from 5 to 20 in increments. 


# Results


<p align="center">
<img src="images/all3_5.png" alt="Image 5" width="200"/>
<img src="images/all3_6.png" alt="Image 6" width="200"/>
<img src="images/all3_7.png" alt="Image 7" width="200"/>
<img src="images/all3_8.png" alt="Image 8" width="200"/>
<img src="images/all3_9.png" alt="Image 9" width="200"/>
<img src="images/all3_10.png" alt="Image 10" width="200"/>
<img src="images/all3_11.png" alt="Image 11" width="200"/>
<img src="images/all3_12.png" alt="Image 12" width="200"/>
<img src="images/all3_13.png" alt="Image 13" width="200"/>
<img src="images/all3_14.png" alt="Image 14" width="200"/>
<img src="images/all3_15.png" alt="Image 15" width="200"/>
<img src="images/all3_16.png" alt="Image 16" width="200"/>
<img src="images/all3_17.png" alt="Image 17" width="200"/>
<img src="images/all3_18.png" alt="Image 18" width="200"/>
<img src="images/all3_19.png" alt="Image 19" width="200"/>
<img src="images/all3_20.png" alt="Image 20" width="200"/>
<img src="images/all3_20.png" alt="Image 21" width="200"/>
</p>
